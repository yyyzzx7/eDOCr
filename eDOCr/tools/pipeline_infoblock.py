from eDOCr.keras_ocr.pipeline import Pipeline
from eDOCr.keras_ocr.recognition import Recognizer
from eDOCr.keras_ocr.tools import read, drawBoxes
from skimage import io
###################---Code Structure---######################################################################
#
#Classes
# |-> row()
#
#############################################################################################################
#
#Functions          
# |-> read_infoblocks(class_list,img) -> returns a list with classes with relevant text, the text predicted in them split in rows and columns,
# |   |-> boxhastext(cl.crop_img,pipeline) -> return the predicted text (unordered) in the class box
# |   |-> order_text(pred,img) -> returns the text (ordered in rows) given unstrutured text
# |   |   |-> get_distance(predictions) -> returns position information from unstructured words
# |   |   |-> distinguish_rows(words) -> order the text in rows of consequent words, identifies if the text belongs to a sentence or not
# |   |   |-> postprocess_text(text) ->

class row():
    def __init__(self, name, y, words, thres,size):
        self.name = name
        self.y=y
        self.words = words
        self.thres = thres
        self.size=size

def get_distance(predictions):
    '''returns position information from unstructured words
    Args: predictions: np array with bounding boxes and character information
    return: detections: list of dictionaries with word information '''
    x0 = 0 
    # Generate dictionary
    detections = []
    for group in predictions:
        # Get center point of bounding box
        top_left_x, top_left_y = group[1][0]
        bottom_right_x, bottom_right_y = group[1][2]
        center_x, center_y = (top_left_x + bottom_right_x)/2, (top_left_y + bottom_right_y)/2
        size=(bottom_right_x-top_left_x,bottom_right_y-top_left_y)
        # Calculate difference between x and origin
        distance_x = center_x - x0
        # Append all results
        detections.append({'text': group[0],'baseline': bottom_right_y,'distance_x': distance_x,'size': size,'thresh': size[1]/2})
    return detections

def distinguish_rows(words):
    """order the text in rows of consequent words, identifies if the text belongs to a sentence or not
    Args: words: list of dictionaries with word information
    return: rows: list of dictionaries with sentence information """
    words =sorted(words,key=lambda x:x['baseline'])
    row0=row('row_0', words[0]['baseline'], [words[0]],words[0]['thresh'],words[0]['size'])
    words=words[1:]
    rows=[row0]
    counter_row=0
    while not len(words)==0:
        words_to_del=[]
        for w in words:
            for r in rows:
                if w['baseline']-r.thres<r.y<w['baseline']+r.thres:
                    if  w['size'][1]-r.thres<r.size[1]<w['size'][1]+r.thres:
                        r.words.append(w)
                        words_to_del.append(w)
        words=[d for d in words if d not in words_to_del]
        if len(words)>0:
            counter_row=counter_row+1
            rows.append(row('row_'+str(counter_row), words[0]['baseline'], [words[0]],words[0]['thresh'],words[0]['size']))
            words=words[1:]
    return rows

def boxhastext(img_,pipeline):
    '''return the predicted text (unordered) from an image
    Args: 
        img_: image
        pipeline: detection and recognition pipeline from keras-ocr
    return:
        pred: np array with bounding boxes and character information'''
    img1=[read(img_)]
    pred=pipeline.recognize(img1)[0]
    
    return pred

def order_text(pred):
    '''returns the text (ordered in rows) from unstructured predictions
    Args: pred: np array with bounding boxes and character information
    return: text: list of strings, each element corresponds to a row'''
    words = get_distance(pred)
    rows = distinguish_rows(words)
    rows = list(filter(lambda x:x!=[], rows))
    text = []
    for r in rows:
        row_text=[]
        w=r.words
        w = sorted(w, key=lambda x:x['distance_x'])
        for each in w:
            row_text.append(each['text'])
        text.append(' '.join(row_text))
    return text

def read_infoblocks(class_list,img,alphabet=None,weight_path=None):
    '''Load alphabet and recognizer into keras-ocr pipeline to return text position and content
    Args:
        class_list: list of rect
        img: np array of engineering drawing
        alphabet: string with characters
        weight_path: path to the recognizer model
    return:
        boxes_w_text: list of dictionaries with id, rect and list of sentences in rect'''
    if alphabet and weight_path: 
        recognizer =Recognizer(alphabet=alphabet)
        recognizer.model.load_weights(weight_path)
        pipeline=Pipeline(recognizer=recognizer)
    else:
        pipeline=Pipeline()
    boxes_w_text=[]
    i=0
    for cl in class_list:        
        if len(cl.children) == 0:
            pred=boxhastext(cl.crop_img,pipeline)
            if pred:
                i+=1
                text={'ID':i,'nominal': '; '.join(order_text(pred))}
                boxes_w_text.append({'rect': cl, 'text':text})
                #img_crop = drawBoxes(image=cl.crop_img,boxes=pred,color=(94, 204, 243), thickness=1, boxes_format="predictions")
                #io.imsave('tests/'+str(i)+'_box.jpg',img_crop)
    return boxes_w_text



    
